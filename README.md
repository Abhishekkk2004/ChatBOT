<h1>Creating a LLM based Chatbot application</h1>
A chatbot which is hosted via streamlit providing a basic chat interface locally in our device using the Ollama framework
<p>In the initial version, We are not having memory function enabled</p>
<hr>
<p>In the next versions, Memory function would be worked upon.</p>
<br>
<h2>Technologies used</h2>
<p> Langchain</p>
<p> Streamlit for hosting</p>
<p> Ollama Framework LLama LLM model </p>
<p> Ollama Framework custom LLM model </p>
<br>
<h2>Future Workings</h2>
<p>End-to-End Deployment</p>
<p>Hosting in any cloud service</p>
<br>
<h2>Update 1</h2>
<p>Memory Function implemented. Now it can have memory just like chatgpt corresponding to an individual user id</p>
<p>Streaming of text while the response is generated</p>
<p>Better UI/UX</p>
<br>
<h2>Upcoming possible updates</h2>
<p>Integration of ChatPDF with ChatBOT making it an wholesome application</p>
<p>Better layouts</p>
<p> Working with agents and tools</p>
